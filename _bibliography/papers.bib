---
---

@InProceedings{ins_refine,
  author="Yan, Lecheng
  and Lyu, Chenyang
  and Xing, Rui
  and Li, Wenxi
  and Samih, Younes
  and Ji, Tianbo
  and Wang, Longyue
  and Jiang, Shaochen",
  editor="Huang, De-Shuang
  and Chen, Haiming
  and Li, Bo
  and Zhang, Qinhu",
  title="Improving Large Language Models for Programmatic Text Understanding via Iterative Instruction Refinement",
  booktitle="Advanced Intelligent Computing Technology and Applications",
  year="2025",
  publisher="Springer Nature Singapore",
  address="Singapore",
  pages="136--148",
  abstract="The capabilities of Large Language Models (LLMs) have greatly improved, showing strong performance in many Natural Language Processing (NLP) tasks. Among these, Programmatic Text Understanding is an important task, which is crucial for the interpretation and generation of structured and executable text. However, current approaches such as expert role-playing prompting and Chain-of-Thought (CoT) prompting for LLMs often fall short in capturing the intricate complexities inherent in programmatic text. To address this limitation, we propose an Iterative Instruction Refinement prompting (IIRP) technique, which iteratively processes programmatic text line by line to enhance comprehension and execution accuracy. Our approach is evaluated across several LLMs including OpenAI's GPT-3.5, DeepSeek, and Qwen-Coder. The results on our evaluation dataset for Programmatic Text Understanding demonstrate that IIRP improves accuracy by an average of 7.22{\%}, with the highest improvement reaching 18.96{\%}, surpassing the results of CoT prompting by an absolute average improvement of 3.86{\%} and the highest improvement of 19.46{\%}. This study not only underscores the potential of LLMs in advancing programmatic text applications but also sets the stage for future innovations in automated text processing and complex task completion.",
  isbn="978-981-96-9994-0"
}

@misc{xie2025finchainsymbolicbenchmarkverifiable,
    abbr={FinChain},
    selected={false},
    title={FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning}, 
    author={Zhuohan Xie and Dhruv Sahnan and Debopriyo Banerjee and Georgi Georgiev and Rushil Thareja and Hachem Madmoun and Jinyan Su and Aaryamonvikram Singh and Yuxia Wang and Rui Xing and Fajri Koto and Haonan Li and Ivan Koychev and Tanmoy Chakraborty and Salem Lahlou and Veselin Stoyanov and Preslav Nakov},
    year={2025},
    eprint={2506.02515},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2506.02515}, 
}

@misc{xing2025analyticalemotionframeworkrumour,
    abbr={RumourEmotion},
    selected={true},
    title={An Analytical Emotion Framework of Rumour Threads on Social Media}, 
    author={Rui Xing and Boyang Sun and Kun Zhang and Preslav Nakov and Timothy Baldwin and Jey Han Lau},
    year={2025},
    eprint={2502.16560},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2502.16560}, 
}

@article{10.1162/tacl_a_00737,
    abbr={LM-Polygraph},
    selected={true},
    author = {Vashurin, Roman and Fadeeva, Ekaterina and Vazhentsev, Artem and Rvanova, Lyudmila and Vasilev, Daniil and Tsvigun, Akim and Petrakov, Sergey and Xing, Rui and Sadallah, Abdelrahman and Grishchenkov, Kirill and Panchenko, Alexander and Baldwin, Timothy and Nakov, Preslav and Panov, Maxim and Shelmanov, Artem},
    title = {Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {13},
    pages = {220-248},
    year = {2025},
    month = {03},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00737},
    url = {https://doi.org/10.1162/tacl\_a\_00737},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00737/2511955/tacl\_a\_00737.pdf},
}

@misc{vazhentsev2024unconditionaltruthfulnesslearningconditional,
    abbr={TAD},
    selected={false},
    title={Unconditional Truthfulness: Learning Conditional Dependency for Uncertainty Quantification of Large Language Models}, 
    author={Artem Vazhentsev and Ekaterina Fadeeva and Rui Xing and Alexander Panchenko and Preslav Nakov and Timothy Baldwin and Maxim Panov and Artem Shelmanov},
    year={2024},
    eprint={2408.10692},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2408.10692}, 
}

@inproceedings{xie-etal-2025-fire,
    abbr={FIRE},
    selected={true},
    title = "{FIRE}: Fact-checking with Iterative Retrieval and Verification",
    author = "Xie, Zhuohan  and
      Xing, Rui  and
      Wang, Yuxia  and
      Geng, Jiahui  and
      Iqbal, Hasan  and
      Sahnan, Dhruv  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.158/",
    doi = "10.18653/v1/2025.findings-naacl.158",
    pages = "2901--2914",
    ISBN = "979-8-89176-195-7",
    abstract = "Fact-checking long-form text is challenging, and it is therefore common practice to break it down into multiple atomic claims. The typical approach to fact-checking these atomic claims involves retrieving a fixed number of pieces of evidence, followed by a verification step. However, this method is usually not cost-effective, as it underutilizes the verification model{'}s internal knowledge of the claim and fails to replicate the iterative reasoning process in human search strategies. To address these limitations, we propose FIRE, a novel agent-based framework that integrates evidence retrieval and claim verification in an iterative manner. Specifically, FIRE employs a unified mechanism to decide whether to provide a final answer or generate a subsequent search query, based on its confidence in the current judgment. We compare FIRE with other strong fact-checking frameworks and find that it achieves slightly better performance while reducing large language model (LLM) costs by an average of 7.6 times and search costs by 16.5 times. These results indicate that FIRE holds promise for application in large-scale fact-checking operations."
}

@inproceedings{xing-etal-2025-evaluating,
    abbr={AttrExp},
    selected={true},
    title = "Evaluating Evidence Attribution in Generated Fact Checking Explanations",
    author = "Xing, Rui  and
      Baldwin, Timothy  and
      Lau, Jey Han",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.282/",
    doi = "10.18653/v1/2025.naacl-long.282",
    pages = "5475--5496",
    ISBN = "979-8-89176-189-6",
    abstract = "Automated fact-checking systems often struggle with trustworthiness, as their generated explanations can include hallucinations. In this work, we explore evidence attribution for fact-checking explanation generation. We introduce a novel evaluation protocol, citation masking and recovery, to assess attribution quality in generated explanations. We implement our protocol using both human annotators and automatic annotators and found that LLM annotation correlates with human annotation, suggesting that attribution assessment can be automated. Finally, our experiments reveal that: (1) the best-performing LLMs still generate explanations that are not always accurate in their attribution; and (2) human-curated evidence is essential for generating better explanations."
}

@misc{li2024lokiopensourcetoolfact,
    abbr={Loki},
    selected={false},
    title={Loki: An Open-Source Tool for Fact Verification}, 
    author={Haonan Li and Xudong Han and Hao Wang and Yuxia Wang and Minghan Wang and Rui Xing and Yilin Geng and Zenan Zhai and Preslav Nakov and Timothy Baldwin},
    year={2024},
    eprint={2410.01794},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2410.01794}, 
}

@inproceedings{wang-etal-2025-genai,
    abbr={GenAIDetect},
    selected={false},
    title = "{G}en{AI} Content Detection Task 1: {E}nglish and Multilingual Machine-Generated Text Detection: {AI} vs. Human",
    author = "Wang, Yuxia  and
      Shelmanov, Artem  and
      Mansurov, Jonibek  and
      Tsvigun, Akim  and
      Mikhailov, Vladislav  and
      Xing, Rui  and
      Xie, Zhuohan  and
      Geng, Jiahui  and
      Puccetti, Giovanni  and
      Artemova, Ekaterina  and
      Su, Jinyan  and
      Ta, Minh Ngoc  and
      Abassy, Mervat  and
      Elozeiri, Kareem Ashraf  and
      El Etter, Saad El Dine Ahmed  and
      Goloburda, Maiya  and
      Mahmoud, Tarek  and
      Tomar, Raj Vardhan  and
      Laiyk, Nurkhan  and
      Mohammed Afzal, Osama  and
      Koike, Ryuto  and
      Kaneko, Masahiro  and
      Aji, Alham Fikri  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Alam, Firoj  and
      Nakov, Preslav  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Chowdhury, Shammur  and
      Shelmanov, Artem  and
      Wang, Yuxia  and
      Artemova, Ekaterina  and
      Kutlu, Mucahid  and
      Mikros, George",
    booktitle = "Proceedings of the 1stWorkshop on GenAI Content Detection (GenAIDetect)",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "International Conference on Computational Linguistics",
    url = "https://aclanthology.org/2025.genaidetect-1.27/",
    pages = "244--261",
    abstract = "We present the GenAI Content Detection Task 1 {--} a shared task on binary machine generated text detection, conducted as a part of the GenAI workshop at COLING 2025. The task consists of two subtasks: Monolingual (English) and Multilingual. The shared task attracted many participants: 36 teams made official submissions to the Monolingual subtask during the test phase and 27 teams {--} to the Multilingual. We provide a comprehensive overview of the data, a summary of the results {--} including system rankings and performance scores {--} detailed descriptions of the participating systems, and an in-depth analysis of submissions."
}

@inproceedings{abassy-etal-2024-llm,
    abbr={LLM-DetectAIve},
    selected={false},
    title = "{LLM}-{D}etect{AI}ve: a Tool for Fine-Grained Machine-Generated Text Detection",
    author = "Abassy, Mervat  and
      Elozeiri, Kareem  and
      Aziz, Alexander  and
      Ta, Minh Ngoc  and
      Tomar, Raj Vardhan  and
      Adhikari, Bimarsha  and
      Ahmed, Saad El Dine  and
      Wang, Yuxia  and
      Mohammed Afzal, Osama  and
      Xie, Zhuohan  and
      Mansurov, Jonibek  and
      Artemova, Ekaterina  and
      Mikhailov, Vladislav  and
      Xing, Rui  and
      Geng, Jiahui  and
      Iqbal, Hasan  and
      Mujahid, Zain Muhammad  and
      Mahmoud, Tarek  and
      Tsvigun, Akim  and
      Aji, Alham Fikri  and
      Shelmanov, Artem  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Hernandez Farias, Delia Irazu  and
      Hope, Tom  and
      Li, Manling",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-demo.35/",
    doi = "10.18653/v1/2024.emnlp-demo.35",
    pages = "336--343",
    abstract = "The ease of access to large language models (LLMs) has enabled a widespread of machine-generated texts, and now it is often hard to tell whether a piece of text was human-written or machine-generated. This raises concerns about potential misuse, particularly within educational and academic domains. Thus, it is important to develop practical systems that can automate the process. Here, we present one such system, LLM-DetectAIve, designed for fine-grained detection. Unlike most previous work on machine-generated text detection, which focused on binary classification, LLM-DetectAIve supports four categories: (i) human-written, (ii) machine-generated, (iii) machine-written, then machine-humanized, and (iv) human-written, then machine-polished. Category (iii) aims to detect attempts to obfuscate the fact that a text was machine-generated, while category (iv) looks for cases where the LLM was used to polish a human-written text, which is typically acceptable in academic writing, but not in education. Our experiments show that LLM-DetectAIve can effectively identify the above four categories, which makes it a potentially useful tool in education, academia, and other domains.LLM-DetectAIve is publicly accessible at https://github.com/mbzuai-nlp/LLM-DetectAIve. The video describing our system is available at https://youtu.be/E8eT{\_}bE7k8c."
}

@inproceedings{xing-etal-2022-automatic,
    abbr={ClimateExp},
    selected={true},
    title = "Automatic Explanation Generation For Climate Science Claims",
    author = "Xing, Rui  and
      Bhatia, Shraey  and
      Baldwin, Timothy  and
      Lau, Jey Han",
    editor = "Parameswaran, Pradeesh  and
      Biggs, Jennifer  and
      Powers, David",
    booktitle = "Proceedings of the 20th Annual Workshop of the Australasian Language Technology Association",
    month = dec,
    year = "2022",
    address = "Adelaide, Australia",
    publisher = "Australasian Language Technology Association",
    url = "https://aclanthology.org/2022.alta-1.16/",
    pages = "122--129",
    abstract = "Climate change is an existential threat to humanity, the proliferation of unsubstantiated claims relating to climate science is manipulating public perception, motivating the need for fact-checking in climate science. In this work, we draw on recent work that uses retrieval-augmented generation for veracity prediction and explanation generation, in framing explanation generation as a query-focused multi-document summarization task. We adapt PRIMERA to the climate science domain by adding additional global attention on claims. Through automatic evaluation and qualitative analysis, we demonstrate that our method is effective at generating explanations."
}

@article{xing2020biorel,
    abbr={BioRel},
    selected={false},
    title={BioRel: towards large-scale biomedical relation extraction},
    author={Xing, Rui and Luo, Jie and Song, Tengwei},
    journal={BMC bioinformatics},
    volume={21},
    pages={1--13},
    year={2020},
    publisher={Springer}
}

@inproceedings{xing-luo-2019-distant,
    abbr={SHTCNN},
    selected={false},
    title = "Distant Supervised Relation Extraction with Separate Head-Tail {CNN}",
    author = "Xing, Rui  and
      Luo, Jie",
    editor = "Xu, Wei  and
      Ritter, Alan  and
      Baldwin, Tim  and
      Rahimi, Afshin",
    booktitle = "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-5533/",
    doi = "10.18653/v1/D19-5533",
    pages = "249--258",
    abstract = "Distant supervised relation extraction is an efficient and effective strategy to find relations between entities in texts. However, it inevitably suffers from mislabeling problem and the noisy data will hinder the performance. In this paper, we propose the Separate Head-Tail Convolution Neural Network (SHTCNN), a novel neural relation extraction framework to alleviate this issue. In this method, we apply separate convolution and pooling to the head and tail entity respectively for extracting better semantic features of sentences, and coarse-to-fine strategy to filter out instances which do not have actual relations in order to alleviate noisy data issues. Experiments on a widely used dataset show that our model achieves significant and consistent improvements in relation extraction compared to statistical and vanilla CNN-based methods."
}

